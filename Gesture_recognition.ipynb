{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BG81L1tJHkZ"
      },
      "source": [
        "# Gesture Recognition\n",
        "In this group project, you are going to build a 3D Conv model that will be able to predict the 5 gestures correctly. Please import the following libraries to get started."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCt-jL_FOjlr",
        "outputId": "cf1835c1-6636-48fd-8097-7a1f74a879ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "kuZ5aUzAJHkf"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from skimage.transform import resize\n",
        "from imageio import imread\n",
        "import abc\n",
        "import datetime\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCYqtH-AJHkk"
      },
      "source": [
        "We set the random seed so that the results don't vary drastically."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(30)\n",
        "import random as rn\n",
        "import keras as Keras\n",
        "\n",
        "rn.seed(30)\n",
        "from keras import backend as K\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "ehfAm6-_tqCv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_doc = np.random.permutation(open('/content/train.csv').readlines())\n",
        "val_doc = np.random.permutation(open('/content/val.csv').readlines())\n",
        "batch_size = 64\n",
        "\n"
      ],
      "metadata": {
        "id": "2TzUjb-3mctj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cropResize(image, y, z):\n",
        "    h, w = image.shape\n",
        "    \n",
        "    # if smaller image crop at center for 120x120\n",
        "    if w == 160:\n",
        "        image = image[:120, 20:140]\n",
        "\n",
        "    # resize every image\n",
        "    return resize(image, (y,z))\n",
        "\n",
        "def normalizeImage(image):\n",
        "    # applying normalization\n",
        "    return image/255.0\n",
        "\n",
        "def preprocessImage(image, y, z):\n",
        "    return normalizeImage(cropResize(image, y, z))\n",
        "\n",
        "def make3dFilter(x):\n",
        "    return tuple([x]*3)\n",
        "\n",
        "def make2dFilter(x):\n",
        "    return tuple([x]*2)\n",
        "\n",
        "def getBatchData(source_path, t, batch, batch_size, img_tensor):\n",
        "    [x,y,z] = [len(img_tensor[0]),img_tensor[1], img_tensor[2]]\n",
        "    img_idx = img_tensor[0]\n",
        "    batch_data = np.zeros((batch_size,x,y,z,3)) # x is the number of images you use for each video, (y,z) is the final size of the input images and 3 is the number of channels RGB\n",
        "    batch_labels = np.zeros((batch_size,5)) # batch_labels is the one hot representation of the output\n",
        "    for folder in range(batch_size): # iterate over the batch_size\n",
        "        imgs = os.listdir(source_path+'/'+ t[folder + (batch*batch_size)].split(';')[0]) # read all the images in the folder\n",
        "        for idx,item in enumerate(img_idx): #  Iterate iver the frames/images of a folder to read them in\n",
        "            image = imread(source_path+'/'+ t[folder + (batch*batch_size)].strip().split(';')[0]+'/'+imgs[item]).astype(np.float32)\n",
        "\n",
        "            #crop the images and resize them. Note that the images are of 2 different shape \n",
        "            #and the conv3D will throw error if the inputs in a batch have different shapes\n",
        "\n",
        "            # separate preprocessImage function is defined for cropping, resizing and normalizing images\n",
        "            batch_data[folder,idx,:,:,0] = preprocessImage(image[:, :, 0], y, z)\n",
        "            batch_data[folder,idx,:,:,1] = preprocessImage(image[:, :, 1], y, z)\n",
        "            batch_data[folder,idx,:,:,2] = preprocessImage(image[:, :, 2], y, z)\n",
        "\n",
        "        batch_labels[folder, int(t[folder + (batch*batch_size)].strip().split(';')[2])] = 1\n",
        "    return batch_data, batch_labels\n",
        "\n",
        "def generator(source_path, folder_list, batch_size, img_tensor):\n",
        "    print( 'Source path = ', source_path, '; batch size =', batch_size)\n",
        "    while True:\n",
        "        t = np.random.permutation(folder_list)\n",
        "        num_batches = int(len(folder_list)/batch_size)\n",
        "        for batch in range(num_batches): # we iterate over the number of batches\n",
        "            yield getBatchData(source_path, t, batch, batch_size, img_tensor)\n",
        "        \n",
        "        # write the code for the remaining data points which are left after full batches\n",
        "        # checking if any remaining batches are there or not\n",
        "        if len(folder_list)%batch_size != 0:\n",
        "            # updated the batch size and yield\n",
        "            batch_size = len(folder_list)%batch_size\n",
        "            yield getBatchData(source_path, t, batch, batch_size, img_tensor)\n",
        "\n"
      ],
      "metadata": {
        "id": "ytEUJ926eDC1"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curr_dt_time = datetime.datetime.now()\n",
        "train_path = '/content/drive/MyDrive/train'\n",
        "val_path = '/content/drive/MyDrive/val'\n",
        "num_train_sequences = len(train_doc)\n",
        "print('# training sequences =', num_train_sequences)\n",
        "num_val_sequences = len(val_doc)\n",
        "print('# validation sequences =', num_val_sequences)\n",
        "num_epochs = 10\n",
        "print ('# epochs =', num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZP6HCeTmHfx",
        "outputId": "649865a0-942e-48e1-d9de-a4609e8d1330"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# training sequences = 663\n",
            "# validation sequences = 100\n",
            "# epochs = 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getImgTensor(n_frames):\n",
        "    img_idx = np.round(np.linspace(0, 29, n_frames)).astype(int)\n",
        "    return [img_idx, 100, 100, 3]\n",
        "\n",
        "# define image tensor size\n",
        "img_tensor = getImgTensor(20)\n",
        "print ('# img_tensor =', img_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5E579G8mOLW",
        "outputId": "beaad64e-f018-49ad-f241-af69c3fdf395"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# img_tensor = [array([ 0,  2,  3,  5,  6,  8,  9, 11, 12, 14, 15, 17, 18, 20, 21, 23, 24,\n",
            "       26, 27, 29]), 100, 100, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, GRU, Flatten, TimeDistributed, Flatten, BatchNormalization, Activation, Dropout, LSTM\n",
        "from keras.layers.convolutional import Conv3D, MaxPooling3D, Conv2D, MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import optimizers"
      ],
      "metadata": {
        "id": "sYUb74cFmOG0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def defineModel(img_tensor):\n",
        "    inputShape = (len(img_tensor[0]), img_tensor[1], img_tensor[2], img_tensor[3])\n",
        "\n",
        "    model = Sequential([\n",
        "        Conv3D(16, make3dFilter(5), activation='relu', input_shape=inputShape),\n",
        "        MaxPooling3D(make3dFilter(2), padding='same'),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        Conv3D(32, make3dFilter(3), activation='relu'),\n",
        "        MaxPooling3D(pool_size=(1,2,2), padding='same'),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        Conv3D(64, make3dFilter(3), activation='relu'),\n",
        "        MaxPooling3D(pool_size=(1,2,2), padding='same'),\n",
        "        BatchNormalization(),\n",
        "\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Dense(64, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        Dropout(0.25),\n",
        "\n",
        "        Dense(5, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=tf.optimizers.Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "    return model\n",
        "\n",
        "model = defineModel(img_tensor)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm0Pu_wPmk-0",
        "outputId": "697b620c-6ba6-407d-bb52-1d08aa988048"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d (Conv3D)             (None, 16, 96, 96, 16)    6016      \n",
            "                                                                 \n",
            " max_pooling3d (MaxPooling3D  (None, 8, 48, 48, 16)    0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 8, 48, 48, 16)    64        \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv3d_1 (Conv3D)           (None, 6, 46, 46, 32)     13856     \n",
            "                                                                 \n",
            " max_pooling3d_1 (MaxPooling  (None, 6, 23, 23, 32)    0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 6, 23, 23, 32)    128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3d_2 (Conv3D)           (None, 4, 21, 21, 64)     55360     \n",
            "                                                                 \n",
            " max_pooling3d_2 (MaxPooling  (None, 4, 11, 11, 64)    0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 4, 11, 11, 64)    256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 30976)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               3965056   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 128)              512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 64)               256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,050,085\n",
            "Trainable params: 4,049,477\n",
            "Non-trainable params: 608\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = generator(train_path, train_doc, batch_size, img_tensor)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_tensor)"
      ],
      "metadata": {
        "id": "jSQ7ocRfmnlg"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "\n"
      ],
      "metadata": {
        "id": "tyhEibJgmtSJ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = 'model_init' + '_' + str(curr_dt_time).replace(' ','').replace(':','_') + '/'\n",
        "    \n",
        "if not os.path.exists(model_name):\n",
        "    os.mkdir(model_name)\n",
        "\n",
        "filepath = model_name + 'model-{epoch:05d}-{loss:.5f}-{categorical_accuracy:.5f}-{val_loss:.5f}-{val_categorical_accuracy:.5f}.h5'\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=False, save_weights_only=False, mode='auto', period=1)\n",
        "\n",
        "LR = ReduceLROnPlateau(monitor='val_loss', factor=0.2, verbose=1, patience=4)\n",
        "\n",
        "# callbacks_list = [checkpoint, LR]\n",
        "callbacks_list = [LR]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WEyHUKqbmu2i",
        "outputId": "b21caea2-51ea-43e8-cd2a-a8599b289572"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model 1 "
      ],
      "metadata": {
        "id": "PNRff3M-fhUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_frames = 16\n",
        "num_epochs = 20\n",
        "batch_size = 64\n",
        "\n",
        "img_tensor = getImgTensor(n_frames)\n",
        "train_generator = generator(train_path, train_doc, batch_size, img_tensor)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_tensor)\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "    \n",
        "inputShape = (len(img_tensor[0]), img_tensor[1], img_tensor[2], img_tensor[3])\n",
        "\n",
        "model1 = Sequential([\n",
        "    Conv3D(16, make3dFilter(5), activation='relu', input_shape=inputShape),\n",
        "    MaxPooling3D(make3dFilter(2), padding='same'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv3D(32, make3dFilter(3), activation='relu'),\n",
        "    MaxPooling3D(pool_size=(1,2,2), padding='same'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Conv3D(64, make3dFilter(3), activation='relu'),\n",
        "    MaxPooling3D(pool_size=(1,2,2), padding='same'),\n",
        "    BatchNormalization(),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Dense(5, activation='softmax')\n",
        "], name=\"conv_3d1\")\n",
        "model1.compile(optimizer=tf.optimizers.Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print(model1.summary())\n",
        "\n",
        "model1_history = model1.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "            callbacks=callbacks_list, validation_data=val_generator, \n",
        "            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtmLvbEvPebj",
        "outputId": "ba25096f-9899-4242-f971-83872510574b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"conv_3d1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv3d_6 (Conv3D)           (None, 12, 96, 96, 16)    6016      \n",
            "                                                                 \n",
            " max_pooling3d_6 (MaxPooling  (None, 6, 48, 48, 16)    0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 6, 48, 48, 16)    64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_7 (Conv3D)           (None, 4, 46, 46, 32)     13856     \n",
            "                                                                 \n",
            " max_pooling3d_7 (MaxPooling  (None, 4, 23, 23, 32)    0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 4, 23, 23, 32)    128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv3d_8 (Conv3D)           (None, 2, 21, 21, 64)     55360     \n",
            "                                                                 \n",
            " max_pooling3d_8 (MaxPooling  (None, 2, 11, 11, 64)    0         \n",
            " 3D)                                                             \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 2, 11, 11, 64)    256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 15488)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               1982592   \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 128)              512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 64)               256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,067,621\n",
            "Trainable params: 2,067,013\n",
            "Non-trainable params: 608\n",
            "_________________________________________________________________\n",
            "None\n",
            "Source path =  /content/drive/MyDrive/train ; batch size = 64\n",
            "Epoch 1/20\n",
            " 5/11 [============>.................] - ETA: 54:43 - loss: 1.7603 - categorical_accuracy: 0.4000  "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "model 2 - Conv 2d + lstm "
      ],
      "metadata": {
        "id": "15GkAYVGPrkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_frames =20\n",
        "num_epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "img_tensor = getImgTensor(n_frames)\n",
        "train_generator = generator(train_path, train_doc, batch_size, img_tensor)\n",
        "val_generator = generator(val_path, val_doc, batch_size, img_tensor)\n",
        "\n",
        "if (num_train_sequences%batch_size) == 0:\n",
        "    steps_per_epoch = int(num_train_sequences/batch_size)\n",
        "else:\n",
        "    steps_per_epoch = (num_train_sequences//batch_size) + 1\n",
        "\n",
        "if (num_val_sequences%batch_size) == 0:\n",
        "    validation_steps = int(num_val_sequences/batch_size)\n",
        "else:\n",
        "    validation_steps = (num_val_sequences//batch_size) + 1\n",
        "    \n",
        "inputShape = (len(img_tensor[0]), img_tensor[1], img_tensor[2], img_tensor[3])\n",
        "\n",
        "model2 = Sequential([\n",
        "    TimeDistributed(Conv2D(16, make2dFilter(3), padding='same', activation='relu'), input_shape=inputShape),\n",
        "    TimeDistributed(BatchNormalization()),\n",
        "    TimeDistributed(MaxPooling2D(make2dFilter(2))),\n",
        "\n",
        "    TimeDistributed(Conv2D(32, make2dFilter(3), padding='same', activation='relu')),\n",
        "    TimeDistributed(BatchNormalization()),\n",
        "    TimeDistributed(MaxPooling2D(make2dFilter(2))),\n",
        "\n",
        "    TimeDistributed(Conv2D(64, make2dFilter(3), padding='same', activation='relu')),\n",
        "    TimeDistributed(BatchNormalization()),\n",
        "    TimeDistributed(MaxPooling2D(make2dFilter(2))),\n",
        "\n",
        "    TimeDistributed(Conv2D(128, make2dFilter(3), padding='same', activation='relu')),\n",
        "    TimeDistributed(BatchNormalization()),\n",
        "    TimeDistributed(MaxPooling2D(make2dFilter(2))),\n",
        "\n",
        "    TimeDistributed(Conv2D(256, make2dFilter(3), padding='same', activation='relu')),\n",
        "    TimeDistributed(BatchNormalization()),\n",
        "    TimeDistributed(MaxPooling2D(make2dFilter(2))),\n",
        "\n",
        "    TimeDistributed(Flatten()),\n",
        "    LSTM(256),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.2),\n",
        "\n",
        "    Dense(5, activation='softmax')\n",
        "], name=\"conv_2d_lstm\")\n",
        "model2.compile(optimizer=tf.optimizers.Adam(), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
        "print(model2.summary())\n",
        "\n",
        "model2_history = model2.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=num_epochs, verbose=1, \n",
        "            callbacks=callbacks_list, validation_data=val_generator, \n",
        "            validation_steps=validation_steps, class_weight=None, workers=1, initial_epoch=0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11kDbeR0mz7W",
        "outputId": "bc742746-046c-4a72-e430-2cb8396b199f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"conv_2d_lstm\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " time_distributed (TimeDistr  (None, 20, 100, 100, 16)  448      \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            " time_distributed_1 (TimeDis  (None, 20, 100, 100, 16)  64       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_2 (TimeDis  (None, 20, 50, 50, 16)   0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDis  (None, 20, 50, 50, 32)   4640      \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_4 (TimeDis  (None, 20, 50, 50, 32)   128       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_5 (TimeDis  (None, 20, 25, 25, 32)   0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_6 (TimeDis  (None, 20, 25, 25, 64)   18496     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_7 (TimeDis  (None, 20, 25, 25, 64)   256       \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_8 (TimeDis  (None, 20, 12, 12, 64)   0         \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_9 (TimeDis  (None, 20, 12, 12, 128)  73856     \n",
            " tributed)                                                       \n",
            "                                                                 \n",
            " time_distributed_10 (TimeDi  (None, 20, 12, 12, 128)  512       \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_11 (TimeDi  (None, 20, 6, 6, 128)    0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_12 (TimeDi  (None, 20, 6, 6, 256)    295168    \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_13 (TimeDi  (None, 20, 6, 6, 256)    1024      \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_14 (TimeDi  (None, 20, 3, 3, 256)    0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " time_distributed_15 (TimeDi  (None, 20, 2304)         0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 256)               2622464   \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,084,133\n",
            "Trainable params: 3,083,141\n",
            "Non-trainable params: 992\n",
            "_________________________________________________________________\n",
            "None\n",
            "Source path =  /content/drive/MyDrive/train ; batch size = 32\n",
            "Epoch 1/30\n",
            "21/21 [==============================] - ETA: 0s - loss: 1.3180 - categorical_accuracy: 0.4299 Source path =  /content/drive/MyDrive/val ; batch size = 32\n",
            "21/21 [==============================] - 1329s 65s/step - loss: 1.3180 - categorical_accuracy: 0.4299 - val_loss: 1.8059 - val_categorical_accuracy: 0.1600 - lr: 0.0010\n",
            "Epoch 2/30\n",
            "21/21 [==============================] - 341s 16s/step - loss: 1.0230 - categorical_accuracy: 0.6066 - val_loss: 2.2279 - val_categorical_accuracy: 0.1875 - lr: 0.0010\n",
            "Epoch 3/30\n",
            "21/21 [==============================] - 299s 14s/step - loss: 0.8418 - categorical_accuracy: 0.6745 - val_loss: 2.3308 - val_categorical_accuracy: 0.0625 - lr: 0.0010\n",
            "Epoch 4/30\n",
            "21/21 [==============================] - 277s 13s/step - loss: 0.9434 - categorical_accuracy: 0.6266 - val_loss: 2.0051 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
            "Epoch 5/30\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.7171 - categorical_accuracy: 0.7227 \n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
            "21/21 [==============================] - 264s 13s/step - loss: 0.7171 - categorical_accuracy: 0.7227 - val_loss: 2.4378 - val_categorical_accuracy: 0.2500 - lr: 0.0010\n",
            "Epoch 6/30\n",
            "21/21 [==============================] - 243s 12s/step - loss: 0.6442 - categorical_accuracy: 0.7283 - val_loss: 2.4700 - val_categorical_accuracy: 0.3125 - lr: 2.0000e-04\n",
            "Epoch 7/30\n",
            "21/21 [==============================] - 250s 12s/step - loss: 0.4129 - categorical_accuracy: 0.8487 - val_loss: 2.8277 - val_categorical_accuracy: 0.2500 - lr: 2.0000e-04\n",
            "Epoch 8/30\n",
            "21/21 [==============================] - 249s 12s/step - loss: 0.4677 - categorical_accuracy: 0.8207 - val_loss: 2.4838 - val_categorical_accuracy: 0.3125 - lr: 2.0000e-04\n",
            "Epoch 9/30\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.3661 - categorical_accuracy: 0.8768 \n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 4.0000001899898055e-05.\n",
            "21/21 [==============================] - 253s 12s/step - loss: 0.3661 - categorical_accuracy: 0.8768 - val_loss: 2.5442 - val_categorical_accuracy: 0.1875 - lr: 2.0000e-04\n",
            "Epoch 10/30\n",
            "21/21 [==============================] - 249s 12s/step - loss: 0.3159 - categorical_accuracy: 0.8964 - val_loss: 2.3553 - val_categorical_accuracy: 0.2500 - lr: 4.0000e-05\n",
            "Epoch 11/30\n",
            "21/21 [==============================] - 246s 12s/step - loss: 0.2982 - categorical_accuracy: 0.9020 - val_loss: 2.4699 - val_categorical_accuracy: 0.1875 - lr: 4.0000e-05\n",
            "Epoch 12/30\n",
            "21/21 [==============================] - 243s 12s/step - loss: 0.2681 - categorical_accuracy: 0.9244 - val_loss: 2.4242 - val_categorical_accuracy: 0.3125 - lr: 4.0000e-05\n",
            "Epoch 13/30\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.2353 - categorical_accuracy: 0.9440 \n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 8.000000525498762e-06.\n",
            "21/21 [==============================] - 251s 12s/step - loss: 0.2353 - categorical_accuracy: 0.9440 - val_loss: 2.6102 - val_categorical_accuracy: 0.1875 - lr: 4.0000e-05\n",
            "Epoch 14/30\n",
            "21/21 [==============================] - 256s 12s/step - loss: 0.2677 - categorical_accuracy: 0.9328 - val_loss: 1.4875 - val_categorical_accuracy: 0.4375 - lr: 8.0000e-06\n",
            "Epoch 15/30\n",
            "21/21 [==============================] - 246s 12s/step - loss: 0.2484 - categorical_accuracy: 0.9188 - val_loss: 2.1557 - val_categorical_accuracy: 0.3750 - lr: 8.0000e-06\n",
            "Epoch 16/30\n",
            "21/21 [==============================] - 255s 12s/step - loss: 0.2366 - categorical_accuracy: 0.9468 - val_loss: 1.6825 - val_categorical_accuracy: 0.3125 - lr: 8.0000e-06\n",
            "Epoch 17/30\n",
            "21/21 [==============================] - 244s 12s/step - loss: 0.2786 - categorical_accuracy: 0.8992 - val_loss: 2.5378 - val_categorical_accuracy: 0.2500 - lr: 8.0000e-06\n",
            "Epoch 18/30\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.2299 - categorical_accuracy: 0.9272 \n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.6000001778593287e-06.\n",
            "21/21 [==============================] - 251s 12s/step - loss: 0.2299 - categorical_accuracy: 0.9272 - val_loss: 2.0155 - val_categorical_accuracy: 0.4375 - lr: 8.0000e-06\n",
            "Epoch 19/30\n",
            "21/21 [==============================] - 248s 12s/step - loss: 0.2428 - categorical_accuracy: 0.9412 - val_loss: 1.7435 - val_categorical_accuracy: 0.5625 - lr: 1.6000e-06\n",
            "Epoch 20/30\n",
            "21/21 [==============================] - 251s 12s/step - loss: 0.2257 - categorical_accuracy: 0.9384 - val_loss: 1.9695 - val_categorical_accuracy: 0.3125 - lr: 1.6000e-06\n",
            "Epoch 21/30\n",
            "21/21 [==============================] - 245s 12s/step - loss: 0.2102 - categorical_accuracy: 0.9468 - val_loss: 0.9396 - val_categorical_accuracy: 0.5625 - lr: 1.6000e-06\n",
            "Epoch 22/30\n",
            "21/21 [==============================] - 249s 12s/step - loss: 0.2391 - categorical_accuracy: 0.9356 - val_loss: 1.5994 - val_categorical_accuracy: 0.3125 - lr: 1.6000e-06\n",
            "Epoch 23/30\n",
            "21/21 [==============================] - 248s 12s/step - loss: 0.2734 - categorical_accuracy: 0.9160 - val_loss: 1.3459 - val_categorical_accuracy: 0.6250 - lr: 1.6000e-06\n",
            "Epoch 24/30\n",
            "21/21 [==============================] - 245s 12s/step - loss: 0.2264 - categorical_accuracy: 0.9440 - val_loss: 2.2120 - val_categorical_accuracy: 0.4375 - lr: 1.6000e-06\n",
            "Epoch 25/30\n",
            "21/21 [==============================] - ETA: 0s - loss: 0.2485 - categorical_accuracy: 0.9104 \n",
            "Epoch 25: ReduceLROnPlateau reducing learning rate to 3.200000264769187e-07.\n",
            "21/21 [==============================] - 243s 12s/step - loss: 0.2485 - categorical_accuracy: 0.9104 - val_loss: 1.0342 - val_categorical_accuracy: 0.6250 - lr: 1.6000e-06\n",
            "Epoch 26/30\n",
            "21/21 [==============================] - 252s 12s/step - loss: 0.2529 - categorical_accuracy: 0.9300 - val_loss: 0.7068 - val_categorical_accuracy: 0.7500 - lr: 3.2000e-07\n",
            "Epoch 27/30\n",
            "21/21 [==============================] - 240s 11s/step - loss: 0.2510 - categorical_accuracy: 0.9272 - val_loss: 1.0929 - val_categorical_accuracy: 0.6250 - lr: 3.2000e-07\n",
            "Epoch 28/30\n",
            "21/21 [==============================] - 277s 13s/step - loss: 0.2224 - categorical_accuracy: 0.9356 - val_loss: 0.9040 - val_categorical_accuracy: 0.6250 - lr: 3.2000e-07\n",
            "Epoch 29/30\n",
            "21/21 [==============================] - 281s 13s/step - loss: 0.2617 - categorical_accuracy: 0.9216 - val_loss: 0.2945 - val_categorical_accuracy: 0.8750 - lr: 3.2000e-07\n",
            "Epoch 30/30\n",
            "21/21 [==============================] - 285s 14s/step - loss: 0.2308 - categorical_accuracy: 0.9328 - val_loss: 0.7395 - val_categorical_accuracy: 0.6875 - lr: 3.2000e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "training accuracy- 92.16\n",
        "val_accuracy - 87.50"
      ],
      "metadata": {
        "id": "iRvw_U_zPESI"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Gesture_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}